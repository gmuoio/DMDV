{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import pymongo\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import meteostat\n",
    "from meteostat import Point, Daily\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to Mongo\n",
    "client = MongoClient('localhost', 27017) #27017 local, 27027 sharding\n",
    "mydb=client['Citibike']\n",
    "mycol=mydb['NewYork']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating year-month combination to automatize the process\n",
    "years=['19','20']\n",
    "combo=[]\n",
    "for y in years:\n",
    "    for m in range(1,13):\n",
    "        m=str(m)\n",
    "        if len(m)==1:\n",
    "            combo.append(y+'0'+m)\n",
    "        else:\n",
    "            combo.append(y+m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1 without download (unzip through python)\n",
    "# advice: do not upload everything one-shot, better in groups (in particular for sharding)\n",
    "for month in combo:\n",
    "\n",
    "    r = requests.get(f'https://s3.amazonaws.com/tripdata/20{month}-citibike-tripdata.csv.zip')\n",
    "  \n",
    "    with zipfile.ZipFile(io.BytesIO(r.content)) as ar:\n",
    "        trip_data = pd.read_csv(ar.open(f'20{month}-citibike-tripdata.csv'))\n",
    "        \n",
    "        # Preprocessing \n",
    "        trip_data.rename(columns = {'start station id': 'S', \n",
    "                                    'end station id': 'E',\n",
    "                                    'birth year': 'BY',\n",
    "                                    'bikeid':'B',\n",
    "                                    'usertype':'U',\n",
    "                                    'gender':'G',\n",
    "                                    'tripduration':'D'}, inplace = True)\n",
    "\n",
    "        trip_data['ST']= pd.to_datetime(trip_data['starttime'])\n",
    "        trip_data['ET']= pd.to_datetime(trip_data['stoptime'])\n",
    "\n",
    "        columns = ['S','E','ST','ET','B','U','BY','G','D']\n",
    "        data_ready = trip_data[columns]\n",
    "        \n",
    "        docs = data_ready.to_dict(orient='records')\n",
    "        \n",
    "        mycol.insert_many(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2 with download\n",
    "root=r\"path\" #ex. windows C:\\Users\\...\\data\\citibike\\\\\n",
    "for month in combo:\n",
    "    trip_data=pd.read_csv(f'{root}20{month}-citibike-tripdata.csv')\n",
    "    trip_data.rename(columns = {'start station id': 'S', \n",
    "                                    'end station id': 'E',\n",
    "                                    'birth year': 'BY',\n",
    "                                    'bikeid':'B',\n",
    "                                    'usertype':'U',\n",
    "                                    'gender':'G',\n",
    "                                    'tripduration':'D'}, inplace = True)\n",
    "\n",
    "    trip_data['ST']= pd.to_datetime(trip_data['starttime'])\n",
    "    trip_data['ET']= pd.to_datetime(trip_data['stoptime'])\n",
    "\n",
    "    columns = ['S','E','ST','ET','B','U','BY','G','D']\n",
    "    data_ready = trip_data[columns]\n",
    "    docs=data_ready.to_dict(orient='records')\n",
    "    mycol.insert_many(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Station data\n",
    "stations = requests.get(\"https://gbfs.citibikenyc.com/gbfs/en/station_information.json\")\n",
    "st = stations.json().get('data').get('stations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning data\n",
    "st_clean = []\n",
    "for stat in st:\n",
    "    station = [stat.get('lat'), stat.get('lon'), stat.get('name'), stat.get('station_id'),stat.get('capacity')]\n",
    "    st_clean.append(station)\n",
    "df_stations = pd.DataFrame(st_clean, columns = ['latitude', 'longitude','name','id','capacity']) \n",
    "df_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving data\n",
    "df_stations.to_csv('stations.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather data\n",
    "lat=df_stations['latitude'].mean()\n",
    "lon=df_stations['longitude'].mean()\n",
    "print(f'''\n",
    "The average latitude is {lat}\n",
    "The average longitude is {lon}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create geographical center based on stations\n",
    "center=Point(lat,lon)\n",
    "# Set time period\n",
    "start = datetime(2019, 1, 1)\n",
    "end = datetime(2020, 12, 31)\n",
    "# Retrieve weather\n",
    "weather = Daily(center, start, end)\n",
    "coverage = weather.coverage()\n",
    "weather = weather.normalize()\n",
    "weather = weather.interpolate()\n",
    "weather = weather.fetch()\n",
    "weather.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and exploration\n",
    "weather['date']=pd.to_datetime(weather['time'])\n",
    "df_weather=weather[['date','tavg','tmin','tmax','prcp','snow','wspd']]\n",
    "df_weather.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature visualization\n",
    "df_weather.plot(y=['tavg', 'tmin', 'tmax'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precipitation visualization\n",
    "df_weather.plot(y=['prcp'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving data\n",
    "df_weather.to_csv('weather.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COVID-19 data\n",
    "df_covid=pd.read_csv('https://raw.githubusercontent.com/nychealth/coronavirus-data/master/trends/data-by-day.csv')\n",
    "df_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and saving data\n",
    "df_covid['date_of_interest']=pd.to_datetime(df_covid['date_of_interest'])\n",
    "df_covid=df_covid.iloc[:,0:10]\n",
    "df_covid.to_csv('covid_nyc.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
